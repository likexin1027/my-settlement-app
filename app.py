import io
import pandas as pd
import streamlit as st
import requests

# ==========================================
# 1. æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
# ==========================================

def normalize_platform(s):
    if pd.isna(s): return ""
    x = str(s).strip().lower()
    if any(k in x for k in ["bç«™", "bilibili", "å“”å“©"]): return "Bç«™"
    if any(k in x for k in ["å°çº¢ä¹¦", "red"]): return "å°çº¢ä¹¦"
    if "è§†é¢‘å·" in x: return "è§†é¢‘å·"
    if any(k in x for k in ["æŠ–éŸ³", "douyin"]): return "æŠ–éŸ³"
    return s

def parse_number(v):
    if pd.isna(v): return 0.0
    if isinstance(v, (int, float)): return float(v)
    s = str(v).strip().replace(",", "")
    if s.endswith("+"): s = s[:-1]
    m = 1.0
    if "äº¿" in s:
        s = s.replace("äº¿", ""); m = 100000000.0
    elif "w" in s.lower():
        s = s.lower().replace("w", ""); m = 10000.0
    elif "ä¸‡" in s:
        s = s.replace("ä¸‡", ""); m = 10000.0
    try:
        return float(s) * m
    except:
        return 0.0

def normalize_label_to_value(lab):
    if pd.isna(lab): return None
    s = str(lab).strip().lower().replace("â‰¥", "").replace("+", "").replace("ä¸‡", "w")
    if "w" in s:
        try: return int(float(s.replace("w", "")) * 10000)
        except: return None
    try: return int(float(s))
    except: return None

def value_to_label(v):
    thresholds = [(1000000, "100w"), (500000, "50w"), (200000, "20w"), (100000, "10w"), (50000, "5w"), (30000, "3w"), (10000, "1w")]
    for t, l in thresholds:
        if v >= t: return f"â‰¥{l}"
    return f"â‰¥{int(v)}"

# ==========================================
# 2. å¥–åŠ±ç»“ç®—æ ¸å¿ƒé€»è¾‘ï¼ˆä¿ç•™åŸåŠŸèƒ½ï¼‰
# ==========================================

def build_reward_lookup(df):
    d = {}
    for plat in df["å¹³å°"].unique():
        sub = df[df["å¹³å°"] == plat].sort_values("é˜ˆå€¼æ•°å€¼", ascending=False)
        d[plat] = [(row["é˜ˆå€¼æ•°å€¼"], float(row["å¥–åŠ±é‡‘é¢"])) for _, row in sub.iterrows()]
    return d

def base_reward(plat, views, lookup):
    if plat not in lookup: return 0.0
    for th, amt in lookup[plat]:
        if views >= th: return amt
    return 0.0

def limited_time_bonus(views, typ):
    if views > 10000 and isinstance(typ, str):
        s = typ.lower()
        if "çƒ­ç‚¹æ¨è" in s or "æ–°æ˜¥ä¸»é¢˜" in s: return 50.0
    return 0.0

def excellence_bonus(plat, typ, likes, views):
    b = 0.0
    if not isinstance(typ, str): return b
    if plat == "Bç«™":
        if "çƒ­æœ" in typ: b += 100.0
        if "çƒ­é—¨" in typ: b += 200.0
    if "çŸ­è§†é¢‘" in typ:
        if likes >= 100000: b += 300.0
        if views >= 2000000: b += 1000.0
    return b

def pick_top5_per_author(df):
    df = df.copy()
    df["æ˜¯å¦è®¡å…¥ç»“ç®—"] = False
    pos_mask = df["æ€»å¥–åŠ±"] > 0
    for author, group in df[pos_mask].groupby("è´¦å·åç§°"):
        idx = group.sort_values("æ€»å¥–åŠ±", ascending=False).head(5).index
        df.loc[idx, "æ˜¯å¦è®¡å…¥ç»“ç®—"] = True
    return df

def filter_banned(df, text_cols):
    banned = ["BUG", "å»ºè®®", "æ‹‰è¸©"]
    mask = pd.Series([False] * len(df), index=df.index)
    for col in text_cols:
        if col in df.columns:
            s = df[col].astype(str)
            for w in banned:
                mask |= s.str.contains(w, case=False, na=False)
    out = df.copy()
    out["æ’é™¤åŸå› "] = ""
    out.loc[mask, "æ’é™¤åŸå› "] = "åŒ…å«æ•æ„Ÿè¯"
    return out[~mask], out[mask]

# ==========================================
# 3. AI å®¡è®¡åŠŸèƒ½
# ==========================================

def chat_with_ai(user_prompt, context_data):
    try:
        if "DEEPSEEK_API_KEY" not in st.secrets:
            return "æœªé…ç½® API Keyã€‚"
        api_key = st.secrets["DEEPSEEK_API_KEY"]
        url = "https://api.deepseek.com/chat/completions"
        headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
        
        system_prompt = (
            "ä½ æ˜¯101ä¿±ä¹éƒ¨é¦–å¸­è´¢åŠ¡å®¡è®¡å®˜ã€‚è¯·åŸºäºæä¾›çš„ç»“ç®—æŠ¥è¡¨æ•°æ®è¿›è¡Œåˆ†æã€‚\n"
            "è¦æ±‚ï¼š1.è®¡ç®—æ¯ä¸‡æ¬¡æ’­æ”¾æ”¶ç›Š(é‡‘é¢/æ’­æ”¾é‡)ï¼›2.æŒ‡å‡ºæ•°æ®å€’æŒ‚ï¼ˆé«˜æ’­æ”¾ä½å¥–é‡‘ï¼‰å¼‚å¸¸ï¼›3.ä¸¥ç¦è§£é‡Šåè¯ï¼Œç›´æ¥å¼•ç”¨å…·ä½“æ•°å­—ã€‚"
        )
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"æŠ¥è¡¨æ•°æ®ï¼š\n{context_data}\n\né—®é¢˜ï¼š{user_prompt}"}
            ],
            "temperature": 0.3
        }
        resp = requests.post(url, json=payload, headers=headers, timeout=60)
        return resp.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"AI å“åº”å¤±è´¥: {str(e)}"

# ==========================================
# 4. ä¸»ç•Œé¢æ¸²æŸ“
# ==========================================

def render():
    st.set_page_config(page_title="101ä¿±ä¹éƒ¨ç»“ç®—å·¥å…·", layout="wide")
    st.title("ğŸ’° 101ä¿±ä¹éƒ¨è´¢åŠ¡ç»“ç®—ä¸­å¿ƒ")

    tabs = st.tabs(["ğŸ“Š ç»“ç®—ä¸­å¿ƒ", "âš™ï¸ è§„åˆ™è®¾ç½®"])

    # --- è§„åˆ™è®¾ç½®æ ‡ç­¾é¡µ ---
    with tabs[1]:
        st.subheader("åŸºç¡€å¥–åŠ±é˜ˆå€¼é…ç½®")
        # é»˜è®¤é…ç½®é€»è¾‘
        thresholds = [1000000, 500000, 200000, 100000, 50000, 30000, 10000]
        rows = [{"å¹³å°": p, "é˜ˆå€¼æ ‡ç­¾": value_to_label(t), "é˜ˆå€¼æ•°å€¼": t, "å¥–åŠ±é‡‘é¢": 0.0} 
                for t in thresholds for p in ["Bç«™", "å°çº¢ä¹¦", "æŠ–éŸ³", "è§†é¢‘å·"]]
        default_map = pd.DataFrame(rows)
        mapping = st.data_editor(default_map, num_rows="dynamic", key="map_editor")
        lookup = build_reward_lookup(mapping)

    # --- ç»“ç®—ä¸­å¿ƒæ ‡ç­¾é¡µ ---
    with tabs[0]:
        uploaded = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶ (éœ€åŒ…å«ï¼šæ¸ é“, æ’­æ”¾é‡, ç‚¹èµ, ä½œå“ç±»å‹, è´¦å·åç§°)", type=["xlsx", "csv"])
        
        if uploaded:
            # 1. è¯»å–æ•°æ®
            try:
                if uploaded.name.endswith('.csv'):
                    df = pd.read_csv(uploaded, encoding='utf-8')
                else:
                    df = pd.read_excel(uploaded)
            except:
                uploaded.seek(0)
                df = pd.read_csv(uploaded, encoding='gbk')

            # 2. å­—æ®µæ£€æŸ¥ä¸æ¸…æ´—
            required = ["æ¸ é“", "æ’­æ”¾é‡", "ç‚¹èµ", "ä½œå“ç±»å‹", "è´¦å·åç§°"]
            if not all(c in df.columns for c in required):
                st.error(f"Excel ç¼ºå°‘å¿…è¦åˆ—ï¼Œè¯·æ£€æŸ¥æ˜¯å¦åŒ…å«: {required}")
                return

            df["æ¸ é“"] = df["æ¸ é“"].apply(normalize_platform)
            df["æ’­æ”¾é‡æ•°å€¼"] = df["æ’­æ”¾é‡"].apply(parse_number)
            df["ç‚¹èµæ•°å€¼"] = df["ç‚¹èµ"].apply(parse_number)

            # 3. æ•æ„Ÿè¯è¿‡æ»¤
            text_cols = [c for c in ["ä½œå“ç±»å‹", "å†…å®¹", "æ ‡é¢˜", "ä½œå“æ ‡é¢˜"] if c in df.columns]
            kept, removed = filter_banned(df, text_cols)

            # 4. å¥–é‡‘è®¡ç®—
            kept["åŸºç¡€å¥–åŠ±"] = kept.apply(lambda x: base_reward(x["æ¸ é“"], x["æ’­æ”¾é‡æ•°å€¼"], lookup), axis=1)
            kept["é™æ—¶å¥–åŠ±"] = kept.apply(lambda x: limited_time_bonus(x["æ’­æ”¾é‡æ•°å€¼"], x["ä½œå“ç±»å‹"]), axis=1)
            kept["ä¼˜ç§€å¥–åŠ±"] = kept.apply(lambda x: excellence_bonus(x["æ¸ é“"], x["ä½œå“ç±»å‹"], x["ç‚¹èµæ•°å€¼"], x["æ’­æ”¾é‡æ•°å€¼"]), axis=1)
            kept["æ€»å¥–åŠ±"] = kept[["åŸºç¡€å¥–åŠ±", "é™æ—¶å¥–åŠ±", "ä¼˜ç§€å¥–åŠ±"]].sum(axis=1)
            
            # 5. Top5 é™åˆ¶
            result = pick_top5_per_author(kept)
            
            # 6. æ•°æ®ç»Ÿè®¡
            summary = result[result["æ˜¯å¦è®¡å…¥ç»“ç®—"]].groupby("è´¦å·åç§°", as_index=False).agg({
                "æ€»å¥–åŠ±": "sum", "æ’­æ”¾é‡æ•°å€¼": "sum"
            }).rename(columns={"æ€»å¥–åŠ±": "ç»“ç®—é‡‘é¢", "æ’­æ”¾é‡æ•°å€¼": "æ€»æ’­æ”¾é‡"})
            
            st.session_state["summary_data"] = summary

            # 7. UI å±•ç¤ºçœ‹æ¿
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("æ€»ç»“ç®—é‡‘é¢", f"Â¥{summary['ç»“ç®—é‡‘é¢'].sum():,.2f}")
            m2.metric("æ€»è¦†ç›–æ’­æ”¾", f"{int(summary['æ€»æ’­æ”¾é‡'].sum()):,}")
            m3.metric("æœ‰æ•ˆä½œè€…æ•°", len(summary))
            m4.metric("è¢«æ’é™¤æ¡ç›®", len(removed))

            st.subheader("ç»“ç®—æ˜ç»†")
            st.dataframe(result, use_container_width=True)

            if not removed.empty:
                with st.expander("æŸ¥çœ‹è¢«æ’é™¤çš„æ•æ„Ÿè¯å†…å®¹"):
                    st.dataframe(removed)

            # 8. ä¸‹è½½æŒ‰é’®
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                result.to_excel(writer, index=False, sheet_name="ç»“ç®—æ˜ç»†")
                summary.to_excel(writer, index=False, sheet_name="æ±‡æ€»")
            st.download_button("ğŸ“¥ ä¸‹è½½ç»“ç®—ç»“æœ", buffer.getvalue(), "101ç»“ç®—ç»“æœ.xlsx")

            # 9. AI åŠ©æ‰‹ç•Œé¢
            st.divider()
            st.subheader("ğŸ¤– 101 ç»“ç®—æ™ºèƒ½å®¡è®¡åŠ©æ‰‹")
            
            if "messages" not in st.session_state:
                st.session_state.messages = []

            for msg in st.session_state.messages:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])

            if user_input := st.chat_input("é—®æˆ‘å…³äºç»“ç®—æ•°æ®çš„åˆ†æ..."):
                st.session_state.messages.append({"role": "user", "content": user_input})
                with st.chat_message("user"): st.markdown(user_input)

                with st.chat_message("assistant"):
                    context = summary.to_string(index=False)
                    ans = chat_with_ai(user_input, context)
                    st.markdown(ans)
                    st.session_state.messages.append({"role": "assistant", "content": ans})

if __name__ == "__main__":
    render()
